{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview\n",
    "In this lesson we'll look at a small selection of common performance metrics and evaluate some algorithms with them on the Titanic dataset you used earlier.\n",
    "\n",
    "There are a few important things to keep in mind here:\n",
    "\n",
    "There is a big difference in performance based on whether a train/test split is used.\n",
    "In general, performance on all metrics is correlated. But some algorithms may end up doing better or worse in different situations.\n",
    "The practical coding of any metric looks almost exactly the same! The difficulty comes in how to make the choice, not in how to implement it.\n",
    "The topics covered in this lesson are:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- Confusion Matrix\n",
    "- F1 score\n",
    "- Mean Absolute Error\n",
    "- Mean Squared Error\n",
    "If you are familiar with these concepts you can skip ahead, but we do recommend completing this lesson as a refresher nonetheless.\n",
    "\n",
    "#### Classification and Regression\n",
    "__Classification__ is about deciding __which categories__ new instances belong to. For example we can organize objects based on whether they are square or round, or we might have data about different passengers on the Titanic like in project 0, and want to know whether or not each passenger survived. Then when we see new objects we can use their features to guess which class they belong to.\n",
    "\n",
    "In __regression__, we want to make __a prediction on continuous data__. For example we might have a list of different people's height, age, and gender and wish to predict their weight. Or perhaps, like in the final project of this course, we have some housing data and wish to make a prediction about the value of a single home.\n",
    "\n",
    "The problem at hand will determine how we choose to evaluate a model.\n",
    "\n",
    "#### Classification Metrics\n",
    "For classification we are dealing with models that make discrete predictions.\n",
    "\n",
    "That is to say these models decide which of a given set of categories a certain data point belongs to. Using a set of data kept for testing, we can measure on this testing set which points were accurately classified, and which were not.\n",
    "\n",
    "Popular classification metrics are:\n",
    "\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- Confusion Matrix\n",
    "- F1 score\n",
    "In the upcoming videos, we will go over each of them.\n",
    "\n",
    "##### Accuracy\n",
    "The most basic and common classification metric is accuracy. Accuracy here is described as the proportion of items classified or labeled correctly.\n",
    "\n",
    "For instance if a classroom has 14 boys and 16 girls, can a facial recognition software correctly identify all boys and all girls? If the software can identify 10 boys and 8 girls, then the software is 60% accurate.\n",
    "\n",
    "- accuracy = number of correctly identified instances / all instances\n",
    "\n",
    "Accuracy is the default metric used in the .score() method for classifiers in sklearn. You can read more in the documentation here.\n",
    "<http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
