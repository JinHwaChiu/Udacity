{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Practical Advice For K-Fold In Sklearn\n",
    "--\n",
    "If our original data comes in some __sort of sorted fashion__, then we will want to __first shuffle the order of the data points before splitting them up into folds, or otherwise randomly assign data points to each fold__. If we want to do this using KFold(), then we can add the__ \"shuffle = True\"__ parameter when setting up the cross-validation object.\n",
    "\n",
    "If we have concerns about __class imbalance__, then we can use the __StratifiedKFold() class__ instead. Where KFold() assigns points to folds without attention to output class, StratifiedKFold() assigns data points to folds so that each fold has approximately the same number of data points of each output class. This is most useful for when we have imbalanced numbers of data points in your outcome classes (e.g. one is rare compared to the others). For this class as well, we can use __\"shuffle = True\" to shuffle the data points' order before splitting into folds.__\n",
    "\n",
    "##### K-Fold CV In Sklearn\n",
    "There's a simple way to randomize the events in sklearn k-fold CV: set the shuffle flag to true.\n",
    "Then you'd go from something like this:\n",
    "\n",
    "```python\n",
    "cv = KFold( len(authors), 2 )\n",
    "#To something like this:\n",
    "cv = KFold( len(authors), 2, shuffle=True )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GridSearchCV \n",
    "\n",
    "__sklearn.grid_search.GridSearchCV__ is a way of systematically working through multiple combinations of parameter tunes, cross-validating as it goes to determine which tune gives the best performance. The beauty is that it can work through many combinations in only a couple extra lines of code.\n",
    "\n",
    "Here's an example from the sklearn documentation:\n",
    "<http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html>\n",
    "\n",
    "```python\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "svr = svm.SVC()\n",
    "clf = grid_search.GridSearchCV(svr, parameters)\n",
    "clf.fit(iris.data, iris.target)\n",
    "```\n",
    "\n",
    "Let's break this down line by line.\n",
    "\n",
    "```python\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]} \n",
    "```\n",
    "\n",
    "A dictionary of the parameters, and the possible values they may take. In this case, they're playing around with the kernel (possible choices are 'linear' and 'rbf'), and C (possible choices are 1 and 10).\n",
    "\n",
    "Then a 'grid' of all the following combinations of values for (kernel, C) are automatically generated:\n",
    "\n",
    "|||\n",
    "|---------|------------|\n",
    "|('rbf', 1)|('rbf', 10)|\n",
    "|(linear', 1)|('linear', 10)|\n",
    "\n",
    "\n",
    "Each is used to train an SVM, and the performance is then assessed using cross-validation.\n",
    "\n",
    "```python\n",
    "svr = svm.SVC() \n",
    "```\n",
    "\n",
    "This looks kind of like creating a classifier, just like we've been doing since the first lesson. But note that the \"clf\" isn't made until the next line--this is just saying what kind of algorithm to use. Another way to think about this is that the \"classifier\" isn't just the algorithm in this case, it's algorithm plus parameter values. Note that there's no monkeying around with the kernel or C; all that is handled in the next line.\n",
    "\n",
    "```python\n",
    "clf = grid_search.GridSearchCV(svr, parameters) \n",
    "```\n",
    "\n",
    "This is where the first bit of magic happens; the classifier is being created. We pass the algorithm (svr) and the dictionary of parameters to try (parameters) and it generates a grid of parameter combinations to try.\n",
    "\n",
    "```python\n",
    "clf.fit(iris.data, iris.target) \n",
    "```\n",
    "\n",
    "And the second bit of magic. The fit function now tries all the parameter combinations, and returns a fitted classifier that's automatically tuned to the optimal parameter combination. You can now access the parameter values via\n",
    "\n",
    "```python\n",
    "clf.best_params_.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L13 Training&Testing Summary\n",
    "---\n",
    "\n",
    "- Numerical tools for handling large amounts of data efficiently\n",
    "- Different types of data, examples of how they arise, and techniques for using them with standard tools\n",
    "- A variety of metrics for evaluating the performance of different algorithms\n",
    "- Basic cross validation techniques for ensuring performance generalizes\n",
    "- Visual representations of learning and complexity, and how to use these to pick effective models\n",
    "\n",
    "Great job getting this far! We'll now put these together in a practical project in which you'll go from a dataset to predictions, learn to explain the pros and cons of possible models, and decide on an optimal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
