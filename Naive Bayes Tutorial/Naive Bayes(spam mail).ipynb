{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1.1: Understanding our dataset\n",
    "--\n",
    "- Parse the data\n",
    "- Dataset from - https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                        sms_message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_table('C:\\Users\\MLUSER\\Documents\\GitHub\\Udacity\\Naive Bayes Tutorial/SMSSpamCollection',\n",
    "                  sep='\\t',\n",
    "                  header=None,\n",
    "                  names=['label','sms_message'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1.2: Data Preprocessing\n",
    "--\n",
    "   - convert labels(str) to binary var(int)\n",
    "   - 0 -> 'ham',not spam\n",
    "   - 1 -> 'spam'\n",
    "- why: beacuse scikit-learn only deal with numerical values\n",
    "\n",
    "-----\n",
    "```python\n",
    "lambda argument: manipulate(argument)\n",
    "map(function_to_apply, list_of_inputs)\n",
    "map(int, [\"12\", \"37\", \"999\"])\n",
    "[12, 37, 999]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                        sms_message\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df.label.map({'ham':0, 'spam':1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2.1: Bag of words\n",
    "--\n",
    "   - BoW concepts: take a piece of text and count the frequency of the words in that text. It is important to note that the BoW concept treats each word individually and the order in which the words occur does not matter.\n",
    "    \n",
    "Step 2.2: Implementing Bag of Words from scratch\n",
    "--\n",
    "\n",
    "```python\n",
    "class sklearn.feature_extraction.text.CountVectorizer(input=’content’, encoding=’utf-8’, decode_error=’strict’, strip_accents=None, lowercase=True, preprocessor=None, tokenizer=None, stop_words=None, token_pattern=’(?u)\\b\\w\\w+\\b’, ngram_range=(1, 1), analyzer=’word’, max_df=1.0, min_df=1, max_features=None, vocabulary=None, binary=False, dtype=<class ‘numpy.int64’>)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Convert all strings to their lower case form.\n",
    "- Let's say we have a document set:\n",
    "```python\n",
    "documents = ['Hello, how are you!',\n",
    "             'Win money, win from home.',\n",
    "             'Call me now.',\n",
    "             'Hello, Call hello you tomorrow?']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello, how are you!', 'win money, win from home.', 'call me now.', 'hello, call hello you tomorrow?']\n"
     ]
    }
   ],
   "source": [
    "doc = ['Hello, how are you!',\n",
    "           'Win money, win from home.',\n",
    "           'Call me now.',\n",
    "           'Hello, Call hello you tomorrow?']\n",
    "doc_lower = []\n",
    "\n",
    "for x in range(len(doc)):\n",
    "    doc_lower.append(doc[x].lower())\n",
    "\n",
    "print doc_lower\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Removing all punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello  how are you ', 'win money  win from home ', 'call me now ', 'hello  call hello you tomorrow ']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "sans_doc_punc = []\n",
    "for i in doc_lower:\n",
    "    #sans_doc_punc.append(i.translate(string.maketrans('', '', string.punctuation)))\n",
    "    sans_doc_punc.append(i.translate(string.maketrans(',!?.','    ')))\n",
    "print sans_doc_punc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['hello', 'how', 'are', 'you'], ['win', 'money', 'win', 'from', 'home'], ['call', 'me', 'now'], ['hello', 'call', 'hello', 'you', 'tomorrow']]\n"
     ]
    }
   ],
   "source": [
    "doc_pre = []\n",
    "for i in sans_doc_punc:\n",
    "    doc_pre.append(i.split())\n",
    "    \n",
    "print doc_pre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Count frequencies\n",
    "```python\n",
    "#Counter dict subclass for counting hashable objects\n",
    "#Tally occurrences of words in a list\n",
    "cnt = Counter()\n",
    "for word in ['red', 'blue', 'red', 'green', 'blue', 'blue']:\n",
    "cnt[word] += 1\n",
    "cnt\n",
    "Counter({'blue': 3, 'red': 2, 'green': 1})\n",
    "```\n",
    "https://docs.python.org/2/library/collections.html?highlight=counter\n",
    "\n",
    "A Counter is a dict subclass for counting hashable objects. It is an unordered collection where elements are stored as dictionary keys and their counts are stored as dictionary values. Counts are allowed to be any integer value including zero or negative counts. The Counter class is similar to bags or multisets in other languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'how': 1, 'you': 1, 'hello': 1, 'are': 1})\n",
      "\n",
      "\n",
      "Counter({'win': 2, 'home': 1, 'from': 1, 'money': 1})\n",
      "\n",
      "\n",
      "Counter({'me': 1, 'now': 1, 'call': 1})\n",
      "\n",
      "\n",
      "Counter({'hello': 2, 'you': 1, 'call': 1, 'tomorrow': 1})\n",
      "\n",
      "\n",
      "[Counter({'how': 1, 'you': 1, 'hello': 1, 'are': 1}), Counter({'win': 2, 'home': 1, 'from': 1, 'money': 1}), Counter({'me': 1, 'now': 1, 'call': 1}), Counter({'hello': 2, 'you': 1, 'call': 1, 'tomorrow': 1})]\n",
      "\n",
      "\n",
      "<class 'collections.Counter'>\n",
      "<type 'list'>\n"
     ]
    }
   ],
   "source": [
    "import collections as colt\n",
    "freq_list = []\n",
    "for i in doc_pre:\n",
    "    freq_count = colt.Counter(i)\n",
    "    freq_list.append(freq_count)\n",
    "    print freq_count\n",
    "    print '\\n'\n",
    "    \n",
    "print freq_list\n",
    "print '\\n'\n",
    "print type(freq_count)\n",
    "print type(freq_list)\n",
    "\n",
    "\n",
    "#freq_count = colt.Counter()\n",
    "#for i in doc_pre:\n",
    "#    for j in i:\n",
    "#        freq_count[j] +=1\n",
    "#print freq_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2.3: Implementing Bag of Words in scikit-learn\n",
    "--\n",
    "\n",
    "- Instructions: Import the sklearn.feature_extraction.text.CountVectorizer method and create an instance of it called 'count_vector'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)\n",
      "<class 'sklearn.feature_extraction.text.CountVectorizer'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vector = CountVectorizer()\n",
    "print count_vector\n",
    "print type(count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
